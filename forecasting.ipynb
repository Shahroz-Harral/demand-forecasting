{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMb6SLnwUUSPJz4ugfxAb8o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shahroz-Harral/demand-forecasting/blob/main/forecasting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Data Preparation"
      ],
      "metadata": {
        "id": "S73GuzQr6M2x"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gceH9nb1vBQc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "data = pd.read_csv('/content/train_0irEZ2H.csv')"
      ],
      "metadata": {
        "id": "IGL0oYsFvLRx"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert week column to datetime\n",
        "data['week'] = pd.to_datetime(data['week'], format='%y/%m/%d')"
      ],
      "metadata": {
        "id": "oiQIRlnJzkB7"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract relevant date features\n",
        "data['year'] = data['week'].dt.year\n",
        "data['month'] = data['week'].dt.month\n",
        "data['day'] = data['week'].dt.day\n",
        "data['week_number'] = data['week'].dt.isocalendar().week"
      ],
      "metadata": {
        "id": "JjgUTWhHzn18"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define features and target\n",
        "features = ['year', 'month', 'day', 'week_number', 'store_id', 'sku_id', 'total_price', 'base_price', 'is_featured_sku', 'is_display_sku']\n",
        "target = 'units_sold'\n"
      ],
      "metadata": {
        "id": "kicVJNhswIMz"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data[features], data[target], test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "OtAZoUg6zqKI"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Feature Engineering\n",
        "\n",
        "Feature engineering is crucial for improving model performance. We'll add more features based on domain knowledge and interactions."
      ],
      "metadata": {
        "id": "59Hl2UvY6SRJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature engineering: creating interaction terms\n",
        "X_train['price_diff'] = X_train['total_price'] - X_train['base_price']\n",
        "X_test['price_diff'] = X_test['total_price'] - X_test['base_price']\n",
        "\n",
        "# Additional feature transformations\n",
        "X_train['total_base_ratio'] = X_train['total_price'] / X_train['base_price']\n",
        "X_test['total_base_ratio'] = X_test['total_price'] / X_test['base_price']"
      ],
      "metadata": {
        "id": "AHK5_0Dey_-H"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Model Selection and Training\n",
        "We will use several models and select the best one based on performance metrics."
      ],
      "metadata": {
        "id": "xAH2BlhIz7UU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "metadata": {
        "id": "QeB0HtytwKby"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize models\n",
        "models = {\n",
        "    'Linear Regression': LinearRegression(),\n",
        "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
        "    'XGBoost': XGBRegressor(n_estimators=100, random_state=42)\n",
        "}"
      ],
      "metadata": {
        "id": "324yKKJPwzpS"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and evaluate models\n",
        "model_performance = {}\n",
        "for model_name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    model_performance[model_name] = mean_squared_error(y_test, y_pred)\n"
      ],
      "metadata": {
        "id": "ZQNQTfBBw2ZU"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print model performance\n",
        "for model_name, mse in model_performance.items():\n",
        "    print(f\"{model_name}: MSE = {mse:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLW8ShL6w2bp",
        "outputId": "4c726e7b-59d1-4e78-b1e0-1a89f1638549"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear Regression: MSE = 2319.4835\n",
            "Random Forest: MSE = 720.1785\n",
            "XGBoost: MSE = 590.8568\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Step 4: Model Evaluation and Hyperparameter Tuning\n",
        "\n",
        "\n",
        "\n",
        "We'll perform hyperparameter tuning on the best model using GridSearchCV."
      ],
      "metadata": {
        "id": "aWjMBoZX0b1k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV"
      ],
      "metadata": {
        "id": "g0kZ1-hBw2d_"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example with Random Forest\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(RandomForestRegressor(random_state=42), param_grid, cv=3, scoring='neg_mean_squared_error')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Best model and parameters\n",
        "best_model = grid_search.best_estimator_\n",
        "print(f\"Best parameters: {grid_search.best_params_}\")"
      ],
      "metadata": {
        "id": "LWCI7sGWw2fz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 5: Forecasting and Performance Improvement**\n",
        "\n",
        "Finally, we use the best model for forecasting and evaluate its performance."
      ],
      "metadata": {
        "id": "wG1HApVX1Jxa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict and evaluate the best model\n",
        "y_pred_best = best_model.predict(X_test)\n",
        "best_mse = mean_squared_error(y_test, y_pred_best)\n",
        "print(f\"Best Model MSE: {best_mse:.4f}\")\n",
        "\n",
        "# Forecast future demand (assuming future data structure is similar)\n",
        "future_weeks = pd.date_range(start=data['week'].max(), periods=30, freq='W')\n",
        "future_data = pd.DataFrame({\n",
        "    'week': future_weeks,\n",
        "    'year': future_weeks.year,\n",
        "    'month': future_weeks.month,\n",
        "    'day': future_weeks.day,\n",
        "    'week_number': future_weeks.isocalendar().week,\n",
        "    'store_id': [8091]*30,  # Assuming a single store for simplicity\n",
        "    'sku_id': [216418]*30,  # Assuming a single SKU for simplicity\n",
        "    'total_price': [100]*30,  # Placeholder values\n",
        "    'base_price': [90]*30,  # Placeholder values\n",
        "    'is_featured_sku': [0]*30,\n",
        "    'is_display_sku': [0]*30\n",
        "})\n",
        "\n",
        "# Add engineered features\n",
        "future_data['price_diff'] = future_data['total_price'] - future_data['base_price']\n",
        "future_data['total_base_ratio'] = future_data['total_price'] / future_data['base_price']\n",
        "\n",
        "# Forecast\n",
        "future_predictions = best_model.predict(future_data[features])\n",
        "\n",
        "# Output the forecasted demand\n",
        "forecast = pd.DataFrame({'week': future_weeks, 'predicted_units_sold': future_predictions})\n",
        "print(forecast)\n"
      ],
      "metadata": {
        "id": "oFkMLY0w1MDA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}